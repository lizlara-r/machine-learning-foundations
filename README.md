# Cocktail-RAG

En este proyecto usamos la base "Cocktail Recipes" ([ver enlace](Documento_Explicativo_CocktailRAG.pdf)) 
para implementar la metodologÃ­a de **Retrieval Augmented Generation (RAG)**.  
El sistema toma ingredientes, recetas y datos de los cÃ³cteles de la base y propone cocteles para preparar segÃºn el input del usuario.  

Usamos **Sentence Transformers** como encoder y **Mistral 7b** como decoder.


# ğŸ¸ Cocktail RAG - Sistema de RecomendaciÃ³n de Cocteles

Un sistema de Retrieval Augmented Generation (RAG) que recomienda cocteles personalizados basÃ¡ndose en ingredientes, recetas y preferencias del usuario.

## ğŸ“‹ DescripciÃ³n

Este proyecto implementa un sistema RAG que utiliza la base de datos "Cocktail Recipes" para proporcionar recomendaciones inteligentes de cocteles. El sistema combina:

- **Encoder**: Sentence Transformers (`all-MiniLM-L6-v2`) para generar embeddings semÃ¡nticos de las recetas
- **Vector Store**: FAISS para bÃºsqueda eficiente de similitud
- **Decoder**: Mistral 7B Instruct para generar respuestas naturales y contextuales

## ğŸ¯ CaracterÃ­sticas

- BÃºsqueda semÃ¡ntica de cocteles basada en descripciones en lenguaje natural
- Recomendaciones personalizadas segÃºn ingredientes disponibles
- Respuestas conversacionales generadas por LLM
- Base de datos de 875+ recetas de cocteles
- Embeddings de 384 dimensiones para captura precisa del contexto

## ğŸ—ƒï¸ Dataset

El proyecto utiliza el dataset [Cocktail Recipes](https://huggingface.co/datasets/brianarbuckle/cocktail_recipes) de Hugging Face.

### Estructura del Dataset (ejemplo de un dato)

```json
{
  "title": "Final Ward",
  "ingredients": [
    "0.75 oz. Rye Whiskey",
    "0.75 oz. Lemon Juice",
    "0.75 oz. Maraschino Liqueur",
    "0.75 oz. Green Chartreuse"
  ],
  "directions": ["shake on ice and strain"],
  "misc": [],
  "source": "Death & Co.",
  "ner": ["whiskey", "chartreuse", "maraschino liqueur"]
}
```

### Campos del Dataset

- **title** (`str`): Nombre del coctel
- **ingredients** (`list` of `str`): Lista de ingredientes con cantidades
- **directions** (`list` of `str`): Pasos de preparaciÃ³n
- **source** (`str`): Origen de la receta
- **ner** (`list` of `str`): Ingredientes clave identificados mediante NER

## ğŸš€ InstalaciÃ³n

```bash
# Subir a Collab
Se debe descargar el archivo y correr en google Collab. Se recomienda hacer uso de una GPU, aunque no es necesario.
```

## ğŸ’» Uso

### EjecuciÃ³n del Notebook

Abre `Cocktail_RAG_Notebook.ipynb` en Google Colab y ejecuta todas las celdas.
Al final del notebook verÃ¡s una casilla de input titulada `Haz una pregunta` donde puedes ingresar inputs.

### Ejemplo de InteracciÃ³n

```python
# Inicializar el sistema
context = encoder("sweet cocktail with rum and pineapple")
response = decoder(context, "sweet cocktail with rum and pineapple")
print(response)
```

### Consultas de Ejemplo
Nota que el decoder usado permite interacciones en espaÃ±ol e ingles.
```
"Dime un coctel con Mezcal con sabor ahumado"
"sweet cocktail with rum and pineapple"
"refreshing drink with gin and citrus"
"strong whiskey-based cocktail"
```

## ğŸ—ï¸ Arquitectura

### 1. Procesamiento de Datos
- NormalizaciÃ³n de listas a texto
- UnificaciÃ³n de campos en documento Ãºnico
- Embeddings generados con Sentence Transformers

### 2. Retrieval (R)
- **Modelo**: `sentence-transformers/all-MiniLM-L6-v2`
- **Dimensiones**: 384
- **Vector Store**: FAISS
- **BÃºsqueda**: Top-k similarity search (k=3)

### 3. Augmentation (A)
- ConstrucciÃ³n de contexto con top-k documentos recuperados
- Formato estructurado para el LLM

### 4. Generation (G)
- **Modelo**: Mistral 7B Instruct v0.2
- **CuantizaciÃ³n**: 4-bit con BitsAndBytes
- **GeneraciÃ³n**: Sampling con temperature=0.7

## ğŸ“Š Especificaciones TÃ©cnicas

| Componente | EspecificaciÃ³n |
|------------|----------------|
| Encoder Model | all-MiniLM-L6-v2 |
| Embedding Dim | 384 |
| Max Tokens (Encoder) | 256 |
| Decoder Model | Mistral-7B-Instruct-v0.2 |
| Quantization | 4-bit |
| Vector Store | FAISS |
| Dataset Size | 875 recetas |

## ğŸ“ Estructura del Proyecto

```
cocktail-rag/
â”‚
â”œâ”€â”€ Cocktail_RAG_Notebook.ipynb             # Notebook principal
â”œâ”€â”€ Documento_Explicativo_CocktailRAG.doc   # Documento que explica el modelo
â”œâ”€â”€ README.md                               # Este archivo
â””â”€â”€ requirements.txt                        # Dependencias del proyecto

```
* No se requiere la descarga de datos.

## ğŸ”§ Requisitos

- Python 3.8+
- GPU recomendada (para Mistral 7B)
- 15GB+ RAM
- Google Colab

## ğŸ“ Notas Importantes

- Los documentos son cortos, por lo que no se requiere chunking
- El modelo utiliza mean pooling para generar embeddings de documentos completos
- La cuantizaciÃ³n 4-bit permite ejecutar Mistral 7B en GPUs consumer
- El notebook usado no tiene un preview, pues al usar un input de chat, GitHub no permite ver previews.

## ğŸ“„ Licencia

Este proyecto utiliza:
- Dataset: [Cocktail Recipes](https://huggingface.co/datasets/brianarbuckle/cocktail_recipes)
- Encoder: Apache 2.0 License
- Decoder: Apache 2.0 License

## ğŸ™ Agradecimientos

- Dataset por [brianarbuckle](https://huggingface.co/brianarbuckle)
- Sentence Transformers por [UKPLab](https://www.sbert.net/)
- Mistral AI por el modelo Mistral 7B

## ğŸ‘¤ Creado por:

Liz Lara, Samuel SuÃ¡rez, Julian FandiÃ±o, Cesar Augusto Espinoza

---

**Nota**: Este proyecto es con fines educativos y de demostraciÃ³n de tÃ©cnicas RAG.
